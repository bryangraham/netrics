{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "746d6be9",
   "metadata": {},
   "source": [
    "# Sparse network asymptotics for logistic regression under possible misspecification: empirical illustration\n",
    "_September 2023_    \n",
    "Bryan S. Graham, UC - Berkeley, bgraham@econ.berkeley.edu\n",
    "\n",
    "This iPython Jupyter notebook reproduces the short empirical illustration in the revised version of my paper \"Sparse network asymptotics for logistic regression under possible misspecification.” This illustration use information on firm-bank relationships from drawn from the Dealscan dataset. The exact extract used in the paper corresponds to syndicated loan deals made in the first six months of 2003 as collected by Jiawei Chen abd Kejun Song (2013) for their paper \"Two-sided matching in the loan market\" in the _International Journal of Industrial Organization_. I am grateful to Jiawei for kindly sharing his estimation sample with me.\n",
    "\n",
    "The scripts below were written for Python 3.6. The Anaconda distribution of Python, available at https://www.continuum.io/downloads, comes bundled with all the scientific computing packages used in this notebook (except for the _geopy_ package which users can install with conda). The notebook additionally uses the _ipt_ and _netrics_ modules that I have created. They are available on my GitHub page (https://github.com/bryangraham).\n",
    "\n",
    "Please feel free to use and modify the material in this notebook for your own research purposes. All I ask is that you cite both the underlying research as well as this codebase (see below for a suggested citation). If you find any errors in what follows I would be happy to hear about them. While I am not able to provide meaningful support for potential users of this code, I am willing to answer questions when/if I have the bandwidth to so.\n",
    "\n",
    "**References:**\n",
    "\n",
    "Chen, Jiawei and Kejun Song. (2013). \"Two-sided matching in the loan market\" _International Journal of Industrial Organization_ 31 (2): 145 - 152.   \n",
    "\n",
    "Graham, Bryan S. (2020). \"Sparse network asymptotics for logistic regression under possible misspecification,” _CEMMAP Working Paper CWP51/20_ (Revised 2024).   \n",
    "\n",
    "**Suggested code citation:**  \n",
    "\n",
    "Graham, Bryan S. (2022). \"Sparse network asymptotics for logistic regression under possible misspecification: empirical illustration Python Jupyter notebook,\" (Version 1.0) [Computer program]. Available at http://bryangraham.github.io/econometrics/ (Accessed 20 September 2022)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d111606",
   "metadata": {},
   "source": [
    "This first block of code loads the main modules used below. The _geopy_ module is used to compute the distance between firm and bank headquarters from latitude and longitude coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53b33392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct Python to plot all figures inline (i.e., not in a separate window)\n",
    "%matplotlib inline\n",
    "\n",
    "# Load libraries\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import geopy.distance\n",
    "\n",
    "# Directory where firm balance sheet and supply-chain raw source files are located\n",
    "data =  '/Users/bgraham/Dropbox/Sites/software/netrics/NotForRepo/matching_dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602f4f10",
   "metadata": {},
   "source": [
    "Next load the netrics package. The Python 2.7 version of this package is registered on PyPi, with a GitHub repository at https://github.com/bryangraham/netrics_py27. For an informal introduction to the package see this [blog post](https://bryangraham.github.io/econometrics/networks/2016/09/15/netrics-module.html). The blog post also includes links to additional resources. The Python 3.6 version of the package is still under development, but currently available code can be found on GitHub at https://github.com/bryangraham/netrics. Once a basic level of functionality and reliability is in place I will register it on PyPi. The netrics package uses some functionality from the ipt package; so this latter package is loaded as well. You can read more about the ipt package at this [blog post](https://bryangraham.github.io/econometrics/causal/inference/2016/05/15/IPT-module.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04c4559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append location of netrics and ipt modules base directory to system path (you can get these off GitHub)\n",
    "# NOTE: only required if permanent install not made (see comments above)\n",
    "import sys\n",
    "sys.path.append('/Users/bgraham/Dropbox/Sites/software/ipt/')\n",
    "sys.path.append('/Users/bgraham/Dropbox/Sites/software/netrics/')\n",
    "\n",
    "# Load ipt and netrics modules\n",
    "import ipt as ipt\n",
    "import netrics as netrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92ac56a",
   "metadata": {},
   "source": [
    "I only use the last six months of data in the Chen and Song (2013) dataset. Ths correspond to a sample syndicated loan deals made during the first six months of 2003."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71f3c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in last period of bank-to-firm loan data (first six months of 2003)\n",
    "bank_firm = pd.read_excel(data + '200306.xls', sheet_name='0306', header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b315cff",
   "metadata": {},
   "source": [
    "Extract index set of firms and banks in the sample. These index sets are used to construct the estimation sample below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "890a61f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "firms = set(bank_firm.firmid.unique())\n",
    "banks = set(bank_firm.bankid.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b273d3",
   "metadata": {},
   "source": [
    "The results reported in the paper use firms total assets (in billions of dollars), bank total assets (also in billions of dollars), and firm and bank locations. Using these data I construct a dyadic level dataset with a record for each possible bank-firm pair. Each record includes the log of the bank's total assets, the log of the firm's total assets, the interaction of these two variables, and the long of the distance between the bank and firm head-quarters in thousands of kilometers. This next block of code constructs this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e26c47af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "# Sets to store indices of firms and banks with missing data\n",
    "firms_inr = set()\n",
    "banks_inr = set()\n",
    "\n",
    "# Construct NxM dyadic dataset\n",
    "for i in firms:\n",
    "    for j in banks:\n",
    "        \n",
    "        # Indicator for when firm i borrowed from bank j \n",
    "        deal_ij = len(bank_firm.loc[(bank_firm['firmid'] == i) & (bank_firm['bankid'] == j)])\n",
    "        \n",
    "        # Total firm assets in billions of dollars\n",
    "        firm_size_i = bank_firm.loc[(bank_firm['firmid'] == i)].iloc[0]['opacity3']/1000\n",
    "                \n",
    "        # Firm location\n",
    "        firm_lat_i = bank_firm.loc[(bank_firm['firmid'] == i)].iloc[0]['latfirm3']\n",
    "        firm_lon_i = bank_firm.loc[(bank_firm['firmid'] == i)].iloc[0]['longfirm3']\n",
    "        \n",
    "        # Total bank assets in billions of dollars\n",
    "        bank_size_j = bank_firm.loc[(bank_firm['bankid'] == j)].iloc[0]['size']/1000000\n",
    "                \n",
    "        # Bank location\n",
    "        bank_lat_j = bank_firm.loc[(bank_firm['bankid'] == j)].iloc[0]['latbankapproximate']\n",
    "        bank_lon_j = bank_firm.loc[(bank_firm['bankid'] == j)].iloc[0]['longbank']\n",
    "        \n",
    "        # Distance between bank and firm in thousands of kilometers\n",
    "        try:\n",
    "            distance_ij = geopy.distance.geodesic((firm_lat_i, firm_lon_i), (bank_lat_j,bank_lon_j)).km/1000    \n",
    "        except:\n",
    "            distance_ij = np.nan\n",
    "                \n",
    "        data.append(pd.DataFrame({'deal' : deal_ij, \\\n",
    "                                  'firm_size' : np.log(firm_size_i), 'bank_size' : np.log(bank_size_j), \\\n",
    "                                  'bank_size_X_firm_size' : np.log(firm_size_i)*np.log(bank_size_j), \\\n",
    "                                  'distance' : np.log(distance_ij)}, index=[(i, j)]))\n",
    "\n",
    "        # Check for item non-response\n",
    "        if (np.isnan(firm_size_i) | np.isnan(firm_lat_i) | np.isnan(firm_lon_i)):\n",
    "            firms_inr.add(i)\n",
    "        if (np.isnan(bank_size_j) | np.isnan(bank_lat_j) | np.isnan(bank_lon_j)):\n",
    "            banks_inr.add(j)    \n",
    "        \n",
    "Z = pd.concat(data)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ab0799",
   "metadata": {},
   "source": [
    "Next I add a multi-index to the dataframe; this is required by the _netrics_ module's _bilogit_ command. The first few rows of the dataframe are displayed below. The _i_ index is for firms, the _j_ index for banks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6a3102a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>deal</th>\n",
       "      <th>firm_size</th>\n",
       "      <th>bank_size</th>\n",
       "      <th>bank_size_X_firm_size</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.426573</td>\n",
       "      <td>1.590567</td>\n",
       "      <td>5.450193</td>\n",
       "      <td>-0.669361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.426573</td>\n",
       "      <td>6.486161</td>\n",
       "      <td>22.225301</td>\n",
       "      <td>-0.531825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.426573</td>\n",
       "      <td>4.569543</td>\n",
       "      <td>15.657871</td>\n",
       "      <td>-0.675604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3.426573</td>\n",
       "      <td>3.325036</td>\n",
       "      <td>11.393478</td>\n",
       "      <td>1.292629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3.426573</td>\n",
       "      <td>1.775735</td>\n",
       "      <td>6.084685</td>\n",
       "      <td>-0.670627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     deal  firm_size  bank_size  bank_size_X_firm_size  distance\n",
       "i j                                                             \n",
       "1 1     0   3.426573   1.590567               5.450193 -0.669361\n",
       "  2     0   3.426573   6.486161              22.225301 -0.531825\n",
       "  3     0   3.426573   4.569543              15.657871 -0.675604\n",
       "  4     0   3.426573   3.325036              11.393478  1.292629\n",
       "  5     0   3.426573   1.775735               6.084685 -0.670627"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up multi-index with firm (i) as the level zero index and bank (j) as the level one index \n",
    "index = pd.MultiIndex.from_tuples(Z.index, names=[\"i\", \"j\"])\n",
    "Z.set_index(index, inplace=True)\n",
    "Z[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae769885",
   "metadata": {},
   "source": [
    "Next I drop any firms and banks with missing regressor data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a765b7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation sample\n",
      "37 out of 388 firms dropped from estimation sample.\n",
      " 0 out of 39 banks dropped from estimation sample.\n"
     ]
    }
   ],
   "source": [
    "# Drop firms with missing values for an regressors\n",
    "for i in firms_inr:\n",
    "    Z.drop(i, level=0, axis=0, inplace=True)\n",
    "\n",
    "# Drop banks with missing values for an regressors    \n",
    "for j in banks_inr:\n",
    "    Z.drop(j, level=1, axis=0, inplace=True)\n",
    "\n",
    "print(\"Estimation sample\")    \n",
    "print(\"{:>2,.0f}\".format(len(firms_inr)) + \" out of \"+ \"{:>2,.0f}\".format(len(firms)) + \" firms dropped from estimation sample.\") \n",
    "print(\"{:>2,.0f}\".format(len(banks_inr)) + \" out of \"+ \"{:>2,.0f}\".format(len(banks)) + \" banks dropped from estimation sample.\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34247106",
   "metadata": {},
   "source": [
    "The final sample of complete cases includes $M=351$ firms and $N=39$ banks. To avoid having firm and bank indices in the dataframe index with no records (which the _bilogit_ command can't handle), I reindex the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10889c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>deal</th>\n",
       "      <th>firm_size</th>\n",
       "      <th>bank_size</th>\n",
       "      <th>bank_size_X_firm_size</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3.426573</td>\n",
       "      <td>1.590567</td>\n",
       "      <td>5.450193</td>\n",
       "      <td>-0.669361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.426573</td>\n",
       "      <td>6.486161</td>\n",
       "      <td>22.225301</td>\n",
       "      <td>-0.531825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3.426573</td>\n",
       "      <td>4.569543</td>\n",
       "      <td>15.657871</td>\n",
       "      <td>-0.675604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3.426573</td>\n",
       "      <td>3.325036</td>\n",
       "      <td>11.393478</td>\n",
       "      <td>1.292629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3.426573</td>\n",
       "      <td>1.775735</td>\n",
       "      <td>6.084685</td>\n",
       "      <td>-0.670627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     deal  firm_size  bank_size  bank_size_X_firm_size  distance\n",
       "i j                                                             \n",
       "1 1     0   3.426573   1.590567               5.450193 -0.669361\n",
       "  2     0   3.426573   6.486161              22.225301 -0.531825\n",
       "  3     0   3.426573   4.569543              15.657871 -0.675604\n",
       "  4     0   3.426573   3.325036              11.393478  1.292629\n",
       "  5     0   3.426573   1.775735               6.084685 -0.670627"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset the multi-index to account for dropped banks and firms\n",
    "Z['dyad'] = Z.index.values\n",
    "index = pd.MultiIndex.from_tuples(Z.index, names=[\"i\", \"j\"])\n",
    "Z.set_index(index, inplace=True)\n",
    "Z.drop('dyad', axis=1, inplace=True)\n",
    "Z[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc207a5",
   "metadata": {},
   "source": [
    "The final dataset includes $NM=388 \\times 39=13,689$ dyads. Only 351 loans out of the 13,689 possible loans are present in the dataset. In this sample each firm borrows just once, but some banks lend to multiple firms. In Chen and Song's full dataset sometimes firms borrow from more than one bank in a given six month interval, but this occurs only rarely (and not at all in the small extract used here). Some basic summary statistics for my estimation sample are included below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc6518ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deal</th>\n",
       "      <th>firm_size</th>\n",
       "      <th>bank_size</th>\n",
       "      <th>bank_size_X_firm_size</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13689.000000</td>\n",
       "      <td>13689.000000</td>\n",
       "      <td>13689.000000</td>\n",
       "      <td>13689.000000</td>\n",
       "      <td>13689.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.025641</td>\n",
       "      <td>-0.034867</td>\n",
       "      <td>2.517779</td>\n",
       "      <td>-0.087787</td>\n",
       "      <td>0.326870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.158068</td>\n",
       "      <td>1.986805</td>\n",
       "      <td>2.695108</td>\n",
       "      <td>7.328194</td>\n",
       "      <td>1.205655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.115668</td>\n",
       "      <td>-4.728808</td>\n",
       "      <td>-39.722889</td>\n",
       "      <td>-16.014247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.288772</td>\n",
       "      <td>1.395820</td>\n",
       "      <td>-3.809633</td>\n",
       "      <td>-0.083440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.100405</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>-0.125462</td>\n",
       "      <td>0.514116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.285084</td>\n",
       "      <td>4.168214</td>\n",
       "      <td>3.495297</td>\n",
       "      <td>1.136673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.776229</td>\n",
       "      <td>6.495266</td>\n",
       "      <td>31.022873</td>\n",
       "      <td>2.103295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               deal     firm_size     bank_size  bank_size_X_firm_size  \\\n",
       "count  13689.000000  13689.000000  13689.000000           13689.000000   \n",
       "mean       0.025641     -0.034867      2.517779              -0.087787   \n",
       "std        0.158068      1.986805      2.695108               7.328194   \n",
       "min        0.000000     -6.115668     -4.728808             -39.722889   \n",
       "25%        0.000000     -1.288772      1.395820              -3.809633   \n",
       "50%        0.000000     -0.100405      3.218876              -0.125462   \n",
       "75%        0.000000      1.285084      4.168214               3.495297   \n",
       "max        1.000000      4.776229      6.495266              31.022873   \n",
       "\n",
       "           distance  \n",
       "count  13689.000000  \n",
       "mean       0.326870  \n",
       "std        1.205655  \n",
       "min      -16.014247  \n",
       "25%       -0.083440  \n",
       "50%        0.514116  \n",
       "75%        1.136673  \n",
       "max        2.103295  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933d1f03",
   "metadata": {},
   "source": [
    "Finally I fit the logistic regression model using the _bilogit_ command. Basic syntax for the command is given below. This is not commerical-grade software, but it should meet many researchers' needs (perhaps after modification). While I not able to provide direct support for this code I very much welcome comments, suggestions and corrections. Feel free to modify and/or improve the code for your own purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8273f5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function bilogit in module netrics.bilogit:\n",
      "\n",
      "bilogit(Y, R, nocons=False, silent=False, cov='DR_bc')\n",
      "    AUTHOR: Bryan S. Graham, UC - Berkeley, bgraham@econ.berkeley.edu, September 2022\n",
      "            (revised September 2023)\n",
      "    PYTHON 3.6\n",
      "    \n",
      "    This function computes bipartite logit regression estimates \n",
      "        \n",
      "    N = number of \"customers\"\n",
      "    M = number of \"products\"\n",
      "    n = NM, dumber of dyads \n",
      "    \n",
      "    \n",
      "    INPUTS:\n",
      "    -------\n",
      "    Y              :  n-length Pandas series with outcome for each\n",
      "                      dyad as elements  \n",
      "    R              :  n x K Pandas dataframe / regressor matrix\n",
      "    nocons         :  if True do NOT append a constant to the regressor\n",
      "                      matrix (default is to append a constant)\n",
      "    silent         :  if True suppress optimization and estimation output\n",
      "    cov            :  covariance matrix estimator\n",
      "                      'jack-knife', 'dense', 'sparse' are allowable choices (see below)\n",
      "    \n",
      "    \n",
      "    The three variance-covariance matrices are as described in the Appendix of \n",
      "    Graham (2022).      \n",
      "    \n",
      "    \n",
      "    OUTPUTS:\n",
      "    --------\n",
      "    theta_BL        : K x 1 vector of coefficient estimates \n",
      "    vcov_theta_BL   : K x K variance-covariance matrix \n",
      "       \n",
      "    FUNCTIONS CALLED : ...logit()...\n",
      "    ----------------   ...print_coef()...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(netrics.bilogit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5155938a",
   "metadata": {},
   "source": [
    "The logit output shown below appears in **Table 3** of in Section 4 of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ce507e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisher-Scoring Derivative check (2-norm): 0.00086652\n",
      "Value of -logL = 6041.447147,  2-norm of score = 4989.097462\n",
      "Value of -logL = 2876.176500,  2-norm of score = 2499.560927\n",
      "Value of -logL = 1932.568338,  2-norm of score = 921.749430\n",
      "Value of -logL = 1695.945578,  2-norm of score = 449.079220\n",
      "Value of -logL = 1493.703937,  2-norm of score = 113.048469\n",
      "Value of -logL = 1420.946949,  2-norm of score = 142.691991\n",
      "Value of -logL = 1420.613298,  2-norm of score = 56.857676\n",
      "Value of -logL = 1409.164145,  2-norm of score = 34.901422\n",
      "Value of -logL = 1399.768941,  2-norm of score = 27.141524\n",
      "Value of -logL = 1399.747610,  2-norm of score = 4.797378\n",
      "Value of -logL = 1399.569893,  2-norm of score = 3.103135\n",
      "Value of -logL = 1399.435284,  2-norm of score = 0.502672\n",
      "Value of -logL = 1399.435276,  2-norm of score = 0.068365\n",
      "Value of -logL = 1399.435261,  2-norm of score = 0.060953\n",
      "Value of -logL = 1399.435234,  2-norm of score = 0.044987\n",
      "Value of -logL = 1399.435204,  2-norm of score = 0.007024\n",
      "Value of -logL = 1399.435203,  2-norm of score = 0.000003\n",
      "Value of -logL = 1399.435203,  2-norm of score = 0.000000\n",
      "Value of -logL = 1399.435203,  2-norm of score = 0.000000\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1399.435203\n",
      "         Iterations: 19\n",
      "         Function evaluations: 22\n",
      "         Gradient evaluations: 22\n",
      "         Hessian evaluations: 19\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "- BILOGIT REGRESSION ESTIMATION RESULTS                                                   -\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "Number of agents (i),       N :             351\n",
      "Number of agents (j),       M :              39\n",
      "Number of dyads,           NM :          13,689\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "Independent variable       Coef.    ( Std. Err.)     (0.95 Confid. Interval )\n",
      "-------------------------------------------------------------------------------------------\n",
      "firm_size                 -0.724084 (  0.094998)     ( -0.910277 , -0.537892)\n",
      "bank_size                  0.615376 (  0.113826)     (  0.392282 ,  0.838470)\n",
      "bank_size_X_firm_size      0.155711 (  0.015496)     (  0.125339 ,  0.186084)\n",
      "distance                  -0.166291 (  0.026162)     ( -0.217566 , -0.115015)\n",
      "constant                  -6.165653 (  0.462722)     ( -7.072570 , -5.258735)\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "NOTE: Standard errors allow for dependence across dyads with agents in common.\n",
      "      (Dense case bias-corrected jack-knife variance estimate). \n",
      "      (Eigenvalues thresholded to make variance pos. def.). \n",
      "Fisher-Scoring Derivative check (2-norm): 0.00086652\n",
      "Value of -logL = 6041.447147,  2-norm of score = 4989.097462\n",
      "Value of -logL = 2876.176500,  2-norm of score = 2499.560927\n",
      "Value of -logL = 1932.568338,  2-norm of score = 921.749430\n",
      "Value of -logL = 1695.945578,  2-norm of score = 449.079220\n",
      "Value of -logL = 1493.703937,  2-norm of score = 113.048469\n",
      "Value of -logL = 1420.946949,  2-norm of score = 142.691991\n",
      "Value of -logL = 1420.613298,  2-norm of score = 56.857676\n",
      "Value of -logL = 1409.164145,  2-norm of score = 34.901422\n",
      "Value of -logL = 1399.768941,  2-norm of score = 27.141524\n",
      "Value of -logL = 1399.747610,  2-norm of score = 4.797378\n",
      "Value of -logL = 1399.569893,  2-norm of score = 3.103135\n",
      "Value of -logL = 1399.435284,  2-norm of score = 0.502672\n",
      "Value of -logL = 1399.435276,  2-norm of score = 0.068365\n",
      "Value of -logL = 1399.435261,  2-norm of score = 0.060953\n",
      "Value of -logL = 1399.435234,  2-norm of score = 0.044987\n",
      "Value of -logL = 1399.435204,  2-norm of score = 0.007024\n",
      "Value of -logL = 1399.435203,  2-norm of score = 0.000003\n",
      "Value of -logL = 1399.435203,  2-norm of score = 0.000000\n",
      "Value of -logL = 1399.435203,  2-norm of score = 0.000000\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1399.435203\n",
      "         Iterations: 19\n",
      "         Function evaluations: 22\n",
      "         Gradient evaluations: 22\n",
      "         Hessian evaluations: 19\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "- BILOGIT REGRESSION ESTIMATION RESULTS                                                   -\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "Number of agents (i),       N :             351\n",
      "Number of agents (j),       M :              39\n",
      "Number of dyads,           NM :          13,689\n",
      "\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "\n",
      "Independent variable       Coef.    ( Std. Err.)     (0.95 Confid. Interval )\n",
      "-------------------------------------------------------------------------------------------\n",
      "firm_size                 -0.724084 (  0.119731)     ( -0.958754 , -0.489415)\n",
      "bank_size                  0.615376 (  0.130221)     (  0.360146 ,  0.870605)\n",
      "bank_size_X_firm_size      0.155711 (  0.019974)     (  0.116564 ,  0.194859)\n",
      "distance                  -0.166291 (  0.042295)     ( -0.249187 , -0.083394)\n",
      "constant                  -6.165653 (  0.563886)     ( -7.270848 , -5.060457)\n",
      "\n",
      "-------------------------------------------------------------------------------------------\n",
      "NOTE: Standard errors allow for dependence across dyads with agents in common.\n",
      "      (Sparse case bias-corrected jack-knife variance estimate). \n"
     ]
    }
   ],
   "source": [
    "# Get outcome variable and drop from regressor matrix\n",
    "Y = Z['deal'].copy(deep=True)\n",
    "Z.drop('deal', axis=1, inplace=True)\n",
    "Z['constant'] = 1\n",
    "\n",
    "[theta_BL, vcov_theta_BL] = netrics.bilogit(Y, Z, nocons=True, silent=False, cov='dense')\n",
    "[theta_BL, vcov_theta_BL] = netrics.bilogit(Y, Z, nocons=True, silent=False, cov='sparse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da1f1be",
   "metadata": {},
   "source": [
    "The estimation results are consistent with Chen and Song's (2013) findings of positive assortive matching by size among banks and firms and also with the importance of spatial proximity. See their paper for greater discussion about the economic and policy implications of this finding. Note, consistent with the sparse asymptotic approximation developed in the paper, the \"dense\" standard errors are smaller than the \"sparse\" ones; particularly for the dyadic regressors (like the log-distance between firm _i_ and bank _j_). This suggests that the extra variance components captured in the sparse approximation are meaningfully large in this particular sample. The estimated standard error for the distance variable is $0.042/0.026=1.61$ longer under the assumption of \"sparseness\" versus \"denseness\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b322257b",
   "metadata": {},
   "source": [
    "This calculates and prints the degree sequence for banks (number of loans made); as well as the inter-quartile range of the sequence. This is useful for calibrating the Monte Carlo data generating process below. In particular the $\\rho$ parameter in the Monte Carlo DGP described in Section 4 of the paper was chosen to match the inter-quartile range of the degree sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82151209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j\n",
      "1       1\n",
      "2     155\n",
      "3      10\n",
      "4       2\n",
      "5       1\n",
      "6      13\n",
      "7       1\n",
      "8       8\n",
      "9       1\n",
      "10      6\n",
      "11      1\n",
      "12      3\n",
      "13      3\n",
      "14      1\n",
      "15      1\n",
      "16      3\n",
      "17      2\n",
      "18     10\n",
      "19      1\n",
      "20     12\n",
      "21      3\n",
      "22      4\n",
      "23      8\n",
      "24     25\n",
      "25     11\n",
      "26      2\n",
      "27      2\n",
      "28      5\n",
      "29      1\n",
      "30      3\n",
      "31     14\n",
      "32      2\n",
      "33     11\n",
      "34     15\n",
      "35      1\n",
      "36      6\n",
      "37      1\n",
      "38      1\n",
      "39      1\n",
      "Name: deal, dtype: int64\n",
      "8.0\n"
     ]
    }
   ],
   "source": [
    "bank_degree = Y.groupby(level=1).sum()\n",
    "print(bank_degree) \n",
    "print(bank_degree.quantile(0.75)-bank_degree.quantile(0.25)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3361bb1",
   "metadata": {},
   "source": [
    "This next block of code executes the empirically calibrated Monte Carlo experiment also reported in Section 4 of the paper. In the empirical Monte Carlo the conditional link probability is assumed to take the logit form (i.e., \"correct specification\" is maintained). The values for the intercept and slope coefficients in this probability are simply those estimated above. The key to calibrating the simulation DGP to the dataset is to construct a latent dyad-level utility shifter that is logistically distributed marginally but that also exhibits the dyadic dependence structure in the paper. I do this by exploiting the reproductive stable property of the gamma distribution. The key cross-dyad dependence parameter, $\\rho$ in the paper, is chosen to match the inter-quartile range of the bank degree-sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90ecb264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monte Carlo design 1 of 3\n",
      "Time required f/ MC rep  500 of 5000: 0.21581125259399414\n",
      "Time required f/ MC rep  1000 of 5000: 0.10178732872009277\n",
      "Time required f/ MC rep  1500 of 5000: 0.08482098579406738\n",
      "Time required f/ MC rep  2000 of 5000: 0.06363415718078613\n",
      "Time required f/ MC rep  2500 of 5000: 0.06827473640441895\n",
      "Time required f/ MC rep  3000 of 5000: 0.12692975997924805\n",
      "Time required f/ MC rep  3500 of 5000: 0.10239005088806152\n",
      "Time required f/ MC rep  4000 of 5000: 0.07051801681518555\n",
      "Time required f/ MC rep  4500 of 5000: 0.0822610855102539\n",
      "Time required f/ MC rep  5000 of 5000: 0.10680794715881348\n",
      "Monte Carlo design 2 of 3\n",
      "Time required f/ MC rep  500 of 5000: 0.08307695388793945\n",
      "Time required f/ MC rep  1000 of 5000: 0.06691408157348633\n",
      "Time required f/ MC rep  1500 of 5000: 0.06562685966491699\n",
      "Time required f/ MC rep  2000 of 5000: 0.06409978866577148\n",
      "Time required f/ MC rep  2500 of 5000: 0.06987190246582031\n",
      "Time required f/ MC rep  3000 of 5000: 0.06362605094909668\n",
      "Time required f/ MC rep  3500 of 5000: 0.05460309982299805\n",
      "Time required f/ MC rep  4000 of 5000: 0.09659218788146973\n",
      "Time required f/ MC rep  4500 of 5000: 0.05914115905761719\n",
      "Time required f/ MC rep  5000 of 5000: 0.0671989917755127\n",
      "Monte Carlo design 3 of 3\n",
      "Time required f/ MC rep  500 of 5000: 0.06338787078857422\n",
      "Time required f/ MC rep  1000 of 5000: 0.06163978576660156\n",
      "Time required f/ MC rep  1500 of 5000: 0.05132794380187988\n",
      "Time required f/ MC rep  2000 of 5000: 0.06138896942138672\n",
      "Time required f/ MC rep  2500 of 5000: 0.06729388236999512\n",
      "Time required f/ MC rep  3000 of 5000: 0.05708599090576172\n",
      "Time required f/ MC rep  3500 of 5000: 0.05716586112976074\n",
      "Time required f/ MC rep  4000 of 5000: 0.05904674530029297\n",
      "Time required f/ MC rep  4500 of 5000: 0.07041406631469727\n",
      "Time required f/ MC rep  5000 of 5000: 0.04998016357421875\n"
     ]
    }
   ],
   "source": [
    "# Values for alpha_v\n",
    "designs = [34, 19, 4]\n",
    "NumDesigns = len(designs)\n",
    "\n",
    " # Number of Monte Carlo simulations\n",
    "S = 5000            \n",
    "\n",
    "#----------------------------------------------------#\n",
    "#- CORE FEATURES OF MONTE CARLO DESIGNS             -#\n",
    "#----------------------------------------------------#\n",
    "    \n",
    "n = 390                 # Sample size, same as in empirical illustration\n",
    "N = 351                 # Number of firms\n",
    "M = 39                  # Number of banks\n",
    "\n",
    "# Initialize matrices for storage of Monte Carlo results\n",
    "theta_hat = np.zeros((S,NumDesigns))\n",
    "coverage  = np.zeros((S,NumDesigns*2))\n",
    "se_hat    = np.zeros((S,NumDesigns*2))\n",
    "\n",
    "#----------------------------------------------------#\n",
    "#- BEGIN MONTE CARLO SIMULATIONS.                   -#\n",
    "#----------------------------------------------------#\n",
    "\n",
    "for b in range(0, NumDesigns):\n",
    "    \n",
    "    # Set random seed and start bth Monte Carlo experiments\n",
    "    # (same seed is used for each design)\n",
    "    np.random.seed(seed=361)\n",
    "    \n",
    "    print(\"Monte Carlo design \" + '%.0f' % (b+1) + \" of \" + '%.0f' % NumDesigns )\n",
    "\n",
    "    #----------------------------------------------#\n",
    "    #- MONTE CARLO SIMULATIONS FOR CURRENT DESIGN -#\n",
    "    #----------------------------------------------#\n",
    "\n",
    "    for s in range(0,S):\n",
    "        start = time.time()\n",
    "    \n",
    "        #-------------------------------------#\n",
    "        #- STEP 1 : SIMULATE BIPARTITE GRAPH -#\n",
    "        #-------------------------------------#\n",
    "    \n",
    "        alpha_a = 1/2\n",
    "        alpha_b = 1/2\n",
    "        beta = 1\n",
    "    \n",
    "        # Simulate consumer and product heterogeneity/effects\n",
    "        A = np.random.gamma(alpha_a, 1/beta, N)\n",
    "        B = np.random.gamma(alpha_b, 1/beta, M)\n",
    "        \n",
    "        iota_M   = np.ones((M,))\n",
    "        i        = np.kron(np.arange(0,N), iota_M)\n",
    "        A_n      = np.kron(A, iota_M) \n",
    "    \n",
    "        iota_N   = np.ones((N,))\n",
    "        j        = np.kron(iota_N, np.arange(0,M))\n",
    "        B_n      = np.kron(iota_N, B) \n",
    "    \n",
    "        \n",
    "    \n",
    "        V        = np.random.gamma(designs[b], 1/beta, (N*M,))\n",
    "        U_star   = A_n + B_n + V\n",
    "        U_star   = sp.stats.gamma.cdf(U_star, alpha_a + alpha_b + designs[b], 0, 1/beta)  \n",
    "        U        = np.log(U_star/(1-U_star))                            \n",
    "    \n",
    "        Y_s      = 1*(Z @ theta_BL >= U.reshape(-1,1))\n",
    "    \n",
    "        #---------------------------------------------#\n",
    "        #- Uncomment this code and iteratively play  -#\n",
    "        #- with the DGP to choose the \"designs\"      -#\n",
    "        #- parameters to match the degree sequence's -#\n",
    "        #- inter-quartile range as described in.     -#\n",
    "        #- Section 4 of the paper.                   -# \n",
    "        #---------------------------------------------#\n",
    "        #bank_degree_s = Y_s.groupby(level=1).sum()\n",
    "        #print(bank_degree_s)\n",
    "        #print(bank_degree_s.quantile(0.75)-bank_degree_s.quantile(0.25)) \n",
    "        \n",
    "        #----------------------------------------------------------#\n",
    "        #- STEP 2 : COMPUTE PSEUDO COMPOSITE LIKELIHOOD ESTIMATES -#\n",
    "        #----------------------------------------------------------#\n",
    "    \n",
    "        #--------------------------------------------------------------------------#\n",
    "        #- Estimation is with the bilogit() command included in the netrics module-#\n",
    "        #--------------------------------------------------------------------------#\n",
    "        \n",
    "        # (i) Dense network standard errors\n",
    "        # ---------------------------------\n",
    "        \n",
    "        [theta_s, vcov_theta_s]= netrics.bilogit(Y_s, Z, nocons=True, silent=True, cov='dense')\n",
    "       \n",
    "        # Save pseudo composite MLE of log-distance coefficient\n",
    "        theta_hat[s,b] = theta_s[3,0]\n",
    "    \n",
    "        # See if true interaction coefficient is inside dense Wald-based confidence interval\n",
    "        coverage[s,b*2]  = (theta_BL[3,0]<=theta_s[3,0] + 1.96*np.sqrt(vcov_theta_s[3,3]))*\\\n",
    "                           (theta_BL[3,0]>=theta_s[3,0] - 1.96*np.sqrt(vcov_theta_s[3,3]))\n",
    "           \n",
    "        # Standard error length\n",
    "        se_hat[s,b*2]    = np.sqrt(vcov_theta_s[3,3])\n",
    "    \n",
    "        # (ii) Bias correction / Sparse network standard errors\n",
    "        # -----------------------------------------------------\n",
    "        \n",
    "        [theta_s, vcov_theta_s]= netrics.bilogit(Y_s, Z, nocons=True, silent=True, cov='sparse')\n",
    "  \n",
    "        # See if true interaction coefficient is inside sparse Wald-based confidence interval\n",
    "        coverage[s,b*2+1]  = (theta_BL[3,0]<=theta_s[3,0] + 1.96*np.sqrt(vcov_theta_s[3,3]))*\\\n",
    "                             (theta_BL[3,0]>=theta_s[3,0] - 1.96*np.sqrt(vcov_theta_s[3,3]))\n",
    "               \n",
    "        # Standard error length\n",
    "        se_hat[s,b*2+1] = np.sqrt(vcov_theta_s[3,3])\n",
    "    \n",
    "        end = time.time()\n",
    "        if (s+1) % 500 == 0:\n",
    "            print(\"Time required f/ MC rep  \" + str(s+1) + \" of \" + str(S) + \": \" + str(end-start))      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e283923a",
   "metadata": {},
   "source": [
    "The next block of code prints out the Monte Carlo summary results reported in **Table 4** of Section 4 of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ef981b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta_0 : -0.16629\n",
      "[0.00217 0.00074 0.00151]\n",
      "[ 0.0006  -0.00091 -0.00053]\n",
      "[0.03568 0.03547 0.04003]\n",
      "[0.0355  0.03479 0.04009]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=5)\n",
    "\n",
    "print(\"theta_0 : \" + '%.5f' % theta_BL[3,0])\n",
    "print(np.mean(theta_hat-theta_BL[3,0],axis=0))\n",
    "print(np.median(theta_hat-theta_BL[3,0],axis=0))\n",
    "print(np.std(theta_hat,axis=0))\n",
    "print((np.quantile(theta_hat, q=0.95, axis=0)-np.quantile(theta_hat, q=0.05, axis=0))/(norm.ppf(0.95)-norm.ppf(0.05)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7c6a927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5256 0.5266 0.5052]\n",
      " [0.928  0.9306 0.9044]]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(coverage,axis=0).reshape((NumDesigns,2)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aea57155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0143  0.01432 0.01482]\n",
      " [0.03326 0.03325 0.0345 ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(se_hat,axis=0).reshape((NumDesigns,2)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a72a2e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0180989336990334"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross check\n",
    "U_star.mean()*2\n",
    "U_star.var()*12"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
